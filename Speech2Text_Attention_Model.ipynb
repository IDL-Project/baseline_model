{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW4P2_template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOnSBSmtkDg-",
        "outputId": "e021f323-3c6b-4f9a-8b63-f12f101f983d"
      },
      "source": [
        "# Inspect GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed May  5 08:06:32 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHuF75ARkPLV"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GV-SJFU7dYVt",
        "outputId": "ed9cfa27-a33b-412b-a274-c44fdee55e78"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqixMlg_dwI-"
      },
      "source": [
        "save_location =  \"./drive/MyDrive/11785/hw4p2/\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3FjZ6lLRQ-t"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBLN6kPCRj-o",
        "outputId": "4a1e0ea7-1627-40ce-e6d0-d16efaff8064"
      },
      "source": [
        "!kaggle competitions download -c 11785-spring2021-hw4p2"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading train_transcripts.npy.zip to /content\n",
            "  0% 0.00/3.76M [00:00<?, ?B/s]\n",
            "100% 3.76M/3.76M [00:00<00:00, 62.4MB/s]\n",
            "Downloading dev_transcripts.npy to /content\n",
            "  0% 0.00/784k [00:00<?, ?B/s]\n",
            "100% 784k/784k [00:00<00:00, 52.3MB/s]\n",
            "Downloading s21_sample.csv to /content\n",
            "  0% 0.00/112k [00:00<?, ?B/s]\n",
            "100% 112k/112k [00:00<00:00, 36.3MB/s]\n",
            "Downloading train.npy.zip to /content\n",
            "100% 3.35G/3.36G [03:23<00:00, 24.7MB/s]\n",
            "100% 3.36G/3.36G [03:24<00:00, 17.7MB/s]\n",
            "Downloading test.npy.zip to /content\n",
            " 99% 181M/183M [00:22<00:00, 6.94MB/s]\n",
            "100% 183M/183M [00:22<00:00, 8.41MB/s]\n",
            "Downloading dev.npy.zip to /content\n",
            " 99% 179M/182M [00:18<00:00, 17.3MB/s]\n",
            "100% 182M/182M [00:18<00:00, 10.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVWnhoWIndFT",
        "outputId": "40f94051-78e8-4a5b-c07a-d4b5ce13ca8c"
      },
      "source": [
        "!unzip dev.npy.zip\n",
        "!unzip test.npy.zip\n",
        "!unzip train.npy.zip\n",
        "!unzip train_transcripts.npy.zip\n",
        "!unzip dev_transcripts.npy.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  dev.npy.zip\n",
            "  inflating: dev.npy                 \n",
            "Archive:  test.npy.zip\n",
            "  inflating: test.npy                \n",
            "Archive:  train.npy.zip\n",
            "  inflating: train.npy               \n",
            "Archive:  train_transcripts.npy.zip\n",
            "  inflating: train_transcripts.npy   \n",
            "unzip:  cannot find or open dev_transcripts.npy.zip, dev_transcripts.npy.zip.zip or dev_transcripts.npy.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1pCOCSqXwjm",
        "outputId": "f8651e43-aa95-4cba-e5af-cce471104de5"
      },
      "source": [
        "!pip install python-Levenshtein"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz (50kB)\n",
            "\r\u001b[K     |██████▌                         | 10kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 18.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30kB 15.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (56.0.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149798 sha256=3e4bb8cf16122d09544cbe74482bdcee160143d175a66032880247b6863561c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/26/73/4b48503bac73f01cf18e52cd250947049a7f339e940c5df8fc\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "HTGPr98x0yjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87949f44-f969-4df0-ec1b-2efaa9d1e8a0"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils as utils\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import random\n",
        "from torch.utils import data\n",
        "import Levenshtein\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "print(cuda, sys.version)\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "np.random.seed(5111785)\n",
        "torch.manual_seed(5111785)\n",
        "\n",
        "LETTER_LIST = ['<sos>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', \\\n",
        "         'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '-', \"'\", '.', '_', '+', ' ', '<eos>']"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True 3.7.10 (default, Feb 20 2021, 21:17:23) \n",
            "[GCC 7.5.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFmcvE1pkDNi"
      },
      "source": [
        "def create_dictionaries(letter_list):\n",
        "    '''\n",
        "    Create dictionaries for letter2index and index2letter transformations\n",
        "    '''\n",
        "    letter2index = {letter:index for index, letter in enumerate(letter_list)}\n",
        "    index2letter = {index:letter for index, letter in enumerate(letter_list)}\n",
        "    return letter2index, index2letter\n",
        "    \n",
        "def transform_letter_to_index(raw_transcripts):\n",
        "    '''\n",
        "    Transforms text input to numerical input by converting each letter \n",
        "    to its corresponding index from letter_list\n",
        "\n",
        "    Args:\n",
        "        raw_transcripts: Raw text transcripts with the shape of (N, )\n",
        "    \n",
        "    Return:\n",
        "        transcripts: Converted index-format transcripts. This would be a list with a length of N\n",
        "    '''  \n",
        "    index_transcript = []\n",
        "    for sentence in raw_transcripts:\n",
        "      try:\n",
        "        sentence = \" \".join([word.decode(\"utf-8\") for word in sentence])\n",
        "      except:\n",
        "        sentence = \" \".join([word for word in sentence])\n",
        "      index_transcript.append([letter2index[LETTER_LIST[0]]]+[letter2index[letter] for letter in sentence]+[letter2index[LETTER_LIST[-1]]])\n",
        "    return index_transcript\n",
        "\n",
        "def transform_index_to_letter(index_transcript):\n",
        "    letter_transcript = []\n",
        "    for idx in index_transcript:\n",
        "      letter_transcript.append(\n",
        "          ''.join(\n",
        "              [LETTER_LIST[int(idx[i])] for i in range(len(idx))]\n",
        "              )\n",
        "          )\n",
        "    \n",
        "    return letter_transcript\n",
        "# Create the letter2index and index2letter dictionary\n",
        "letter2index, index2letter = create_dictionaries(LETTER_LIST)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJukRb802lQI"
      },
      "source": [
        "# Load the training, validation and testing data\n",
        "train_data = np.load('train.npy', allow_pickle=True, encoding='bytes')\n",
        "valid_data = np.load('dev.npy', allow_pickle=True, encoding='bytes')\n",
        "# test_data = np.load('test.npy', allow_pickle=True, encoding='bytes')\n",
        "\n",
        "# Load the training, validation raw text transcripts\n",
        "raw_train_transcript = np.load('train_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
        "raw_valid_transcript = np.load('dev_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
        "\n",
        "# TODO: Convert the raw text transcripts into indexes\n",
        "train_transcript = transform_letter_to_index(raw_train_transcript)\n",
        "valid_transcript = transform_letter_to_index(raw_valid_transcript)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3tJ3osX7rmz"
      },
      "source": [
        "# train_transcript[0]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BklwAcjs7AQk"
      },
      "source": [
        "# raw_train_transcript"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhSD0FOXm5Q6"
      },
      "source": [
        "class MyDataset(data.Dataset):\n",
        "    def __init__(self, X, Y=None):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # For testing set, return only x\n",
        "        if self.Y == None:\n",
        "            return torch.tensor(self.X[index].astype(np.float32))\n",
        "        # For training and validation set, return x and y\n",
        "        else:\n",
        "            return torch.tensor(self.X[index].astype(np.float32)), torch.tensor(self.Y[index])\n",
        "\n",
        "def collate_train_val(data):\n",
        "    \"\"\"\n",
        "    Return:\n",
        "        pad_x: the padded x (training/validation speech data) \n",
        "        pad_y: the padded y (text labels - transcripts)\n",
        "        x_len: the length of x\n",
        "        y_len: the length of y\n",
        "    \"\"\"\n",
        "    Xs, ys, x_lengths, y_lengths = [], [], [], []\n",
        "\n",
        "    for x,y in data:\n",
        "        Xs.append(x)\n",
        "        ys.append(y)\n",
        "        x_lengths.append(x.shape[0])\n",
        "        y_lengths.append(len(y))\n",
        "    return (rnn_utils.pad_sequence(Xs, batch_first=False), x_lengths), (rnn_utils.pad_sequence(ys, batch_first=True), y_lengths)\n",
        "\n",
        "def collate_test(data):\n",
        "    \"\"\"\n",
        "    Return:\n",
        "        pad_x: the padded x (testing speech data) \n",
        "        x_len: the length of x\n",
        "    \"\"\"\n",
        "    Xs, x_lengths = [], []\n",
        "\n",
        "    for x in data:\n",
        "      Xs.append(x)\n",
        "      x_lengths.append(x.shape[0])\n",
        "\n",
        "    return (rnn_utils.pad_sequence(Xs, batch_first=False), x_lengths)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejlh0-Zh9NsP"
      },
      "source": [
        "BATCH_SIZE = 64"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "OJKdna5VnIJM"
      },
      "source": [
        "# Create datasets\n",
        "train_dataset = MyDataset(train_data, train_transcript)\n",
        "valid_dataset = MyDataset(valid_data, valid_transcript)\n",
        "# test_dataset = MyDataset(test_data)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = data.DataLoader(train_dataset, batch_size\n",
        "                               =BATCH_SIZE, shuffle=True, \n",
        "                               num_workers=4, pin_memory=True, collate_fn=collate_train_val)\n",
        "valid_loader = data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
        "                               num_workers=4, pin_memory=True, collate_fn=collate_train_val)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfpIMUDzCvT3"
      },
      "source": [
        "class pBLSTM(nn.Module):\n",
        "    '''\n",
        "    Pyramidal BiLSTM\n",
        "    Read paper and understand the concepts and then write your implementation here.\n",
        "    '''\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(pBLSTM, self).__init__()\n",
        "        self.blstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
        "\n",
        "    def forward(self, x, lens):\n",
        "      x, hidden_state = self.blstm(x)\n",
        "      #print(\"input >>>>>\",x.shape)\n",
        "      x, output_lens = rnn_utils.pad_packed_sequence(x, batch_first=True)\n",
        "      #print(\"shape:\", x.shape)\n",
        "      if x.shape[1] % 2 != 0:\n",
        "        x = x[:,:-1,:]\n",
        "        #print(\"shape:\", x.shape)\n",
        "      x = x.reshape(x.shape[0], x.shape[1]//2, x.shape[2]*2)\n",
        "      #print(\"after reshape:\", x.shape)\n",
        "      out = rnn_utils.pack_padded_sequence(x, output_lens//2, enforce_sorted=False, batch_first=True) # repack for next layer\n",
        "      # print(\"out shape:\", out.shape)\n",
        "      return out, np.array(output_lens)//2"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F9zAQR95P55"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    '''\n",
        "    Encoder takes the utterances as inputs and returns the key, value and unpacked_x_len.\n",
        "    Key and value are linear projections of the output from pBLSTM network for the laster.\n",
        "    '''\n",
        "    def __init__(self, input_dim, encoder_hidden_dim, key_value_size=128):\n",
        "        super(Encoder, self).__init__()\n",
        "        # The first LSTM at the very bottom\n",
        "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=encoder_hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
        "\n",
        "\n",
        "        # TODO: Define the blocks of pBLSTMs\n",
        "        # ...\n",
        "        self.pBiLSTM1 = pBLSTM(2*encoder_hidden_dim, encoder_hidden_dim//2)\n",
        "        self.pBiLSTM2 = pBLSTM(2*encoder_hidden_dim, encoder_hidden_dim//2)\n",
        "        self.pBiLSTM3 = pBLSTM(2*encoder_hidden_dim, encoder_hidden_dim//2)\n",
        "        # The linear transformation for producing Key and Value for attention\n",
        "        # Since you are using bidirectional LSTM, be careful about the size of hidden dimension\n",
        "        self.key_network = nn.Linear(encoder_hidden_dim*2, key_value_size)\n",
        "        self.value_network = nn.Linear(encoder_hidden_dim*2, key_value_size)\n",
        "\n",
        "    def forward(self, x, x_len):\n",
        "      # print(x_len)\n",
        "      # print(x.shape)\n",
        "      # Pass through the first LSTM at the very bottom\n",
        "      packed_sequence = rnn_utils.pack_padded_sequence(x, x_len, enforce_sorted=False, batch_first=False) \n",
        "      packed_out, _ = self.lstm(packed_sequence)\n",
        "      # unpacked, _ = rnn_utils.pad_packed_sequence(packed_out)\n",
        "      \n",
        "\n",
        "      # TODO: Pass through the pBLSTM blocks\n",
        "      # ...\n",
        "      layer_out, new_len = self.pBiLSTM1(packed_out, x_len)\n",
        "      layer_out, new_len = self.pBiLSTM2(layer_out, new_len)\n",
        "      layer_out, new_len = self.pBiLSTM3(layer_out, new_len)\n",
        "      # Unpack the sequence and get the Key and Value for attention\n",
        "      pblstm_out, unpacked_x_len = rnn_utils.pad_packed_sequence(layer_out, batch_first=True)\n",
        "      \n",
        "      keys = self.key_network(pblstm_out)\n",
        "      values = self.value_network(pblstm_out)\n",
        "      return keys, values, unpacked_x_len"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqu-MUM8TjUO"
      },
      "source": [
        "def plot_attention(attention):\n",
        "    plt.clf()\n",
        "    sns.heatmap(attention, cmap='hot')\n",
        "    plt.show()\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    '''\n",
        "    Attention is calculated using key, value and query from Encoder and decoder.\n",
        "    Below are the set of operations you need to perform for computing attention:\n",
        "        energy = bmm(key, query)\n",
        "        attention = softmax(energy)\n",
        "        context = bmm(attention, value)\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "    def forward(self, query, key, value, mask):\n",
        "        # Compute (batch_size, max_len) attention logits. \"bmm\" stands for \"batch matrix multiplication\".\n",
        "        # Input shape of bmm:  (batch_szie, max_len, hidden_size), (batch_size, hidden_size, 1) \n",
        "        # Output shape of bmm: (batch_size, max_len, 1)\n",
        "        energy = torch.bmm(key, query.unsqueeze(2)).squeeze(2)\n",
        "        \n",
        "        # Create an (batch_size, max_len) boolean mask for all padding positions\n",
        "        # Make use of broadcasting: (1, max_len), (batch_size, 1) -> (batch_size, max_len)\n",
        "        mask_lengths = torch.arange(key.size(1)).unsqueeze(0) >= mask.unsqueeze(1)\n",
        "        \n",
        "        # Set attention logits at padding positions to negative infinity.\n",
        "        energy.masked_fill_(mask_lengths.to(device), -1e9)\n",
        "        \n",
        "        # Take softmax over the \"source length\" dimension.\n",
        "        attention = nn.functional.softmax(energy, dim=1)\n",
        "        \n",
        "        # Compute attention-weighted sum of context vectors\n",
        "        # Input shape of bmm: (batch_size, 1, max_len), (batch_size, max_len, hidden_size) \n",
        "        # Output shape of bmm: (batch_size, 1, hidden_size)\n",
        "        context = torch.bmm(attention.unsqueeze(1), value).squeeze(1)\n",
        "        \n",
        "        # attention vectors are returned for visualization\n",
        "        return context, attention"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcTC4cK95TYT"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    '''\n",
        "    As mentioned in a previous recitation, each forward call of decoder deals with just one time step.\n",
        "    Thus we use LSTMCell instead of LSTM here.\n",
        "    The output from the seond LSTMCell can be used as query for calculating attention.\n",
        "    In place of value that we get from the attention, this can be replace by context we get from the attention.\n",
        "    Methods like Gumble noise and teacher forcing can also be incorporated for improving the performance.\n",
        "    '''\n",
        "    def __init__(self, vocab_size, decoder_hidden_dim, embed_dim, key_value_size=128):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=letter2index['<eos>'])\n",
        "        self.lstm1 = nn.LSTMCell(input_size=embed_dim + key_value_size, hidden_size=decoder_hidden_dim)\n",
        "        self.lstm2 = nn.LSTMCell(input_size=decoder_hidden_dim, hidden_size=key_value_size)\n",
        "      \n",
        "        self.attention = Attention()     \n",
        "        self.vocab_size = vocab_size\n",
        "        self.character_prob = nn.Linear(2 * key_value_size, vocab_size)\n",
        "        self.key_value_size = key_value_size\n",
        "\n",
        "    def forward(self, key, value, encoder_len, y=None, mode='train', teacher_force_prob=0.3):\n",
        "        '''\n",
        "        Args:\n",
        "            key :(B, T, key_value_size) - Output of the Encoder Key projection layer\n",
        "            value: (B, T, key_value_size) - Output of the Encoder Value projection layer\n",
        "            y: (T, text_len) - Batch input of text with text_length\n",
        "            mode: Train or eval mode\n",
        "        Return:\n",
        "            predictions: the character perdiction probability \n",
        "        '''\n",
        "\n",
        "        B, key_seq_max_len, key_value_size = key.shape\n",
        "\n",
        "\n",
        "        if mode == 'train':\n",
        "            max_len =  y.shape[1]\n",
        "            char_embeddings = self.embedding(y)\n",
        "        else:\n",
        "            max_len = 600\n",
        "\n",
        "        # TODO: Create the attention mask here (outside the for loop rather than inside) to aviod repetition\n",
        "        # ...\n",
        "        attention_mask = []\n",
        "        \n",
        "        predictions = []\n",
        "        prediction = torch.zeros(B, 1).to(device)\n",
        "        hidden_states = [None, None] \n",
        "        \n",
        "        # TODO: Initialize the context. Be careful here\n",
        "        context = value[:, 0, :]\n",
        "        \n",
        "        for i in range(max_len):\n",
        "            if mode == 'train':\n",
        "                # TODO: Implement (1) Teacher Forcing and (2) Gumble Noise techniques here\n",
        "                # ...\n",
        "                # teacher forcing\n",
        "                if np.random.random() < teacher_force_prob:\n",
        "                  char_embed = char_embeddings[:,i,:]\n",
        "                else:\n",
        "                  prediction = F.gumbel_softmax(prediction, tau=1)\n",
        "                  char_embed = self.embedding(prediction.argmax(dim=-1))\n",
        "            else:\n",
        "                char_embed = self.embedding(prediction.argmax(dim=-1))\n",
        "\n",
        "            y_context = torch.cat([char_embed, context], dim=1)\n",
        "            hidden_states[0] = self.lstm1(y_context, hidden_states[0])\n",
        "\n",
        "            lstm1_hidden = hidden_states[0][0]\n",
        "            hidden_states[1] = self.lstm2(lstm1_hidden, hidden_states[1])\n",
        "            output = hidden_states[1][0]\n",
        "            \n",
        "            # TODO: Compute attention from the output of the second LSTM Cell\n",
        "            # ...\n",
        "            context, attention = self.attention(output,key, value, encoder_len)\n",
        "            \n",
        "            output_context = torch.cat([output, context], dim=1)\n",
        "            prediction = self.character_prob(output_context)\n",
        "            predictions.append(prediction.unsqueeze(1))\n",
        "            \n",
        "            attention_mask.append(attention.detach().cpu().numpy())\n",
        "        attention_mask = np.array(attention_mask)\n",
        "\n",
        "        mask = attention_mask[:,0, :encoder_len[0]]\n",
        "        return torch.cat(predictions, dim=1), mask"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d35FEZhz5Uhx"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    '''\n",
        "    We train an end-to-end sequence to sequence model comprising of Encoder and Decoder.\n",
        "    This is simply a wrapper \"model\" for your encoder and decoder.\n",
        "    '''\n",
        "    def __init__(self, input_dim, vocab_size, encoder_hidden_dim, decoder_hidden_dim, embed_dim, key_value_size=128):\n",
        "        super(Seq2Seq,self).__init__()\n",
        "        self.encoder = Encoder(input_dim, encoder_hidden_dim, key_value_size=key_value_size)\n",
        "        self.decoder = Decoder(vocab_size, decoder_hidden_dim, embed_dim, key_value_size=key_value_size)\n",
        "\n",
        "    def forward(self, x, x_len, y=None, mode='train'):\n",
        "        key, value, encoder_len = self.encoder(x, x_len)\n",
        "        predictions, attention = self.decoder(key, value, encoder_len, y=y, mode=mode)\n",
        "        return predictions, attention"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jzpCjd9R5VYV"
      },
      "source": [
        "def train(model, train_loader, criterion, optimizer, mode):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    \n",
        "    # 0) Iterate through your data loader\n",
        "    for batch, (X, y) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      # 1) Set the inputs to the device.\n",
        "      X_data, X_len = X\n",
        "      X_data = X_data.to(device)\n",
        "      # X_len = X_len.to(device)\n",
        "      y_data, y_len = y\n",
        "      y_data = y_data.to(device)\n",
        "      y_data_in = y_data[:,:-1]\n",
        "      y_data_out = y_data[:,1:]\n",
        "      #print(\"targets>>>\",y_data_out.shape)\n",
        "      #print(\"y_data\",y_data_out.shape)\n",
        "\n",
        "      # 2) Pass your inputs, and length of speech into the model.\n",
        "      predictions, att = model(X_data, X_len, y_data_in)\n",
        "      #print(\"pred>>>\",predictions.shape)\n",
        "      # 3) Generate a mask based on the lengths of the text\n",
        "      #    Ensure the mask is on the device and is the correct shape. \n",
        "      mask = torch.Tensor(np.zeros(y_data_in.shape)).to(device)\n",
        "      for i in range(len(y_len)):\n",
        "        mask[i, :y_len[i]] = 1\n",
        "      mask.to(device)\n",
        "      mask = mask.view(-1)\n",
        "      \n",
        "      # 4. Calculate the loss and mask it to remove the padding part\n",
        "      pred = predictions.contiguous().view(-1,predictions.size(-1))#figure out the meaning later\n",
        "      # print(\"pred2>>>\",pred.shape)\n",
        "      y_data_out1 = y_data_out.contiguous().view(-1)#.shape\n",
        "      # print(\"y_data>>>\",y_data_out1.shape)\n",
        "      loss = criterion(pred, y_data_out1)\n",
        "\n",
        "      masked_loss = torch.sum(loss*mask)\n",
        "      \n",
        "      # 5. Backward on the masked loss\n",
        "      masked_loss.backward()\n",
        "      \n",
        "      # 6. Optional: Use torch.nn.utils.clip_grad_norm(model.parameters(), 2) to clip the gradient\n",
        "      # torch.nn.utils.clip_grad_norm(model.parameters(), 2)\n",
        "\n",
        "      # 7. Take a step with your optimizer\n",
        "      optimizer.step()\n",
        "      \n",
        "      # 8. print the statistic (loss, edit distance and etc.) for analysis\n",
        "      running_loss += float(masked_loss.item())/int(torch.sum(mask).item())\n",
        "\n",
        "      #if  batch % 20 == 0:\n",
        "    print('Train_loss: ', running_loss/batch)\n",
        "    # torch.cuda.empty_cache()\n",
        "    return att"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb209cQoM1iM"
      },
      "source": [
        "def convert(logits, eos_token, prediction):\n",
        "  if prediction:\n",
        "    probas = F.softmax(logits, dim=2)\n",
        "    preds = torch.argmax(probas, dim=2)\n",
        "  else:\n",
        "    preds = logits\n",
        "  pred_list = []\n",
        "\n",
        "  for i in range(preds.size(0)):\n",
        "    eos_idx = (preds[i] ==  eos_token).nonzero()\n",
        "\n",
        "    eos_idx = (len(preds[i])-1) if eos_idx.nelement() == 0 else eos_idx[0]\n",
        "\n",
        "    pred_list.append(preds[i, :eos_idx])\n",
        "\n",
        "  return pred_list"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRH1IHsd9PFF"
      },
      "source": [
        "def get_text(logits, vocabulary, prediction=False):\n",
        "  eos_token = vocabulary.index('<eos>')\n",
        "  pred_list = convert(logits, eos_token, prediction)\n",
        "\n",
        "  out_str = transform_index_to_letter(pred_list)\n",
        "  return out_str"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6uqAwQCT3oU"
      },
      "source": [
        "def calc_ED(prediction, target):\n",
        "  for i, pred in enumerate(prediction):\n",
        "    dist = []\n",
        "    if i < len(target):\n",
        "      dist = Levenshtein.distance(pred, target[i])\n",
        "  return np.mean(dist)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOJA3sqW9MHB"
      },
      "source": [
        "def val(model, valid_loader, epoch):\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    edit_distance = 0\n",
        "    \n",
        "    # 0) Iterate through your data loader\n",
        "    for batch, (X, y) in enumerate(valid_loader):\n",
        "      # print(\"X\",np.array(X[0]).shape)\n",
        "      # print(\"y\",np.array(y[0]).shape)\n",
        "      # optimizer.zero_grad()\n",
        "      # 1) Set the inputs to the device.\n",
        "      X_data, X_len = X\n",
        "      X_data = X_data.to(device)\n",
        "      y_data, y_len = y\n",
        "      y_data = y_data.to(device)\n",
        "      y_data_in = y_data[:,:-1]\n",
        "      y_data_out = y_data[:,1:]\n",
        "\n",
        "      # 2) Pass your inputs, and length of speech into the model.\n",
        "      predictions, att = model(X_data, X_len, y_data, mode='test')\n",
        "\n",
        "      predicted_text = get_text(predictions.data.cpu(), LETTER_LIST, True)\n",
        "      target_text = get_text(y_data_out.data.cpu(), LETTER_LIST)\n",
        "      if epoch%5 == 0:\n",
        "        print(\"TARGET:\", target_text)\n",
        "        print(\"PREDICTED:\", predicted_text)\n",
        "      \n",
        "      edit_distance += calc_ED(predicted_text, target_text)\n",
        "\n",
        "      torch.nn.utils.clip_grad_norm(model.parameters(), 2)\n",
        "    \n",
        "    edit_distance /= len(valid_loader)\n",
        "    print('Distance: ', edit_distance)\n",
        "    torch.save(model.state_dict(), f\"{save_location}Trial1Epoch{epoch}.pth\")\n",
        "    return edit_distance"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jb82fQE-glu"
      },
      "source": [
        "# # TODO: Define your model and put it on the device here\n",
        "# # ...\n",
        "model = Seq2Seq(input_dim=40, vocab_size=len(LETTER_LIST), encoder_hidden_dim=512, \n",
        "                decoder_hidden_dim=512, embed_dim=512, key_value_size=128)\n",
        "model = model.to(device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xJMLSzHRDof",
        "outputId": "4ef0322a-8be1-4616-84bc-25856a1190da"
      },
      "source": [
        "state_dict = torch.load(f'{save_location}Trial1Epoch20.pth')\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtnTI-s8q4ls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ebb79b4-77f2-48d7-85bf-f692050a912a"
      },
      "source": [
        "n_epochs = 20\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(reduction='none').to(device)\n",
        "mode = 'train'\n",
        "\n",
        "for epoch in range(21, 30):#Try with another 10 epochs\n",
        "  print(f\"Epoch {epoch}...\")\n",
        "  start_time = time.time()\n",
        "  \n",
        "  att = train(model, train_loader, criterion, optimizer, mode)\n",
        "  plot_attention(att)\n",
        "  \n",
        "  train_time = time.time()\n",
        "  print(f\"Train time: {(train_time - start_time)/60} min\")\n",
        "\n",
        "  val(model, valid_loader, epoch)\n",
        "  \n",
        "  val_time = time.time()\n",
        "  print(f\"Val time: {(val_time - train_time)/60} min\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 21...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9sAAqS-5raB"
      },
      "source": [
        "#### Test set prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L9QPptM6THq"
      },
      "source": [
        "test_data = np.load('test.npy', allow_pickle=True, encoding='bytes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGNXBMqq6ZuW"
      },
      "source": [
        "test_dataset = MyDataset(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwBbtNMf6jiB"
      },
      "source": [
        "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, \n",
        "                               num_workers=4, pin_memory=True, collate_fn=collate_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q8zjX8Y53QU"
      },
      "source": [
        "def test(model, test_loader):\n",
        "    words = []\n",
        "    model.to(device)\n",
        "    start = time.time()\n",
        "    #loss= 0\n",
        "    cumm_loss =0.0\n",
        "    # 1) Iterate through your loader\n",
        "    for i,(X) in enumerate(test_loader):\n",
        "      optimizer.zero_grad()\n",
        "      # 2) Use torch.autograd.set_detect_anomaly(True) to get notices about gradient explosion\n",
        "      torch.autograd.set_detect_anomaly(True)\n",
        "      # 3) Set the inputs to the device.\n",
        "      X_data, X_length = (X) #1344, 64, 40\n",
        "      #print(target_data.shape)\n",
        "      sequence_length = X_data.shape[2]\n",
        "      X_data = X_data.to(device)\n",
        "      X_length =  torch.LongTensor(X_length).to(torch.int)\n",
        "      #print(\"shape input\",input_data.shape,input_length.shape)\n",
        "  \n",
        "\n",
        "      # 4) Pass your inputs, and length of speech into the model.\n",
        "      predicted,att = model(X_data,X_length, mode='test')\n",
        "      #print('pre',predicted.shape)\n",
        "      predicted_words = get_text(predicted.data.cpu(), LETTER_LIST,True)\n",
        "      words.append(predicted_words)\n",
        "    words = np.concatenate(words)\n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LprjHyMV5p-6"
      },
      "source": [
        "final_prediction = test(model,test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNU3PP5U8Hlb"
      },
      "source": [
        "import pandas as pd\n",
        "ids = np.arange(len(final_prediction))\n",
        "out_dict = {\"id\":ids,\"label\":final_prediction}\n",
        "df = pd.DataFrame(out_dict)\n",
        "df.to_csv(f\"{save_location}submission2.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIhC1-hR8ez2"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKXMT_OslWWD"
      },
      "source": [
        "!kaggle competitions submit -c 11785-homework-4-part-2-las-slack -f {save_location}submission1.csv -m \"First attempt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQDjQijs1_wi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}